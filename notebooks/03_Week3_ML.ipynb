{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1869cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üöÄ EXOHABITAI ‚Äî LEVEL-1200 WEEK3 ML PIPELINE (FINAL)\n",
    "# AUTO ROOT DETECTION + AUTO DATASET FINDER + BACKEND READY\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "print(\"üöÄ ExoHabitAI ‚Äî Week3 ML Pipeline Started\")\n",
    "\n",
    "# ============================================================\n",
    "# üåå AUTO PROJECT ROOT DETECTOR (ULTRA SAFE)\n",
    "# ============================================================\n",
    "\n",
    "def find_project_root():\n",
    "    path = os.getcwd()\n",
    "    for _ in range(6):\n",
    "        if os.path.exists(os.path.join(path, \"backend\")):\n",
    "            return path\n",
    "        path = os.path.dirname(path)\n",
    "    return os.getcwd()\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "\n",
    "print(\"üì° Project Root:\", PROJECT_ROOT)\n",
    "\n",
    "# ============================================================\n",
    "# üî• AUTO DATASET SCANNER (NO MORE FILE ERRORS)\n",
    "# ============================================================\n",
    "\n",
    "SEARCH_DIRS = [\n",
    "    os.path.join(PROJECT_ROOT, \"data\", \"processed\"),\n",
    "    os.path.join(PROJECT_ROOT, \"notebooks\", \"data\", \"processed\"),\n",
    "    PROJECT_ROOT\n",
    "]\n",
    "\n",
    "TARGET_FILES = [\n",
    "    \"model_ready_exoplanets.csv\",\n",
    "    \"processed_model_ready_exoplanets.csv\",\n",
    "    \"final_model_ready_exoplanets.csv\"\n",
    "]\n",
    "\n",
    "DATA_PATH = None\n",
    "\n",
    "for folder in SEARCH_DIRS:\n",
    "    for file in TARGET_FILES:\n",
    "        test = os.path.join(folder, file)\n",
    "        if os.path.exists(test):\n",
    "            DATA_PATH = test\n",
    "            break\n",
    "    if DATA_PATH:\n",
    "        break\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå No model-ready dataset found.\\n\"\n",
    "        \"üëâ Run preprocessing notebook FIRST.\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Using Dataset:\", DATA_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATASET (SAFE MODE)\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "\n",
    "print(\"üìä Dataset Shape:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# TARGET VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "if \"habitability\" not in df.columns:\n",
    "    raise ValueError(\"‚ùå 'habitability' column missing\")\n",
    "\n",
    "target = \"habitability\"\n",
    "\n",
    "# Keep only numeric features for ML stability\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "X = numeric_df.drop(columns=[target])\n",
    "y = numeric_df[target]\n",
    "\n",
    "print(\"üß† Feature Count:\", X.shape[1])\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# ============================================================\n",
    "# MODEL PIPELINES\n",
    "# ============================================================\n",
    "\n",
    "models = {\n",
    "\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=3000, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=12,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN + EVALUATE\n",
    "# ============================================================\n",
    "\n",
    "for name, pipe in models.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Training {name}\")\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    results.append((name, auc, pipe))\n",
    "\n",
    "# ============================================================\n",
    "# AUTO SELECT BEST MODEL\n",
    "# ============================================================\n",
    "\n",
    "best_name, best_auc, best_model = sorted(results, key=lambda x:x[1], reverse=True)[0]\n",
    "\n",
    "print(\"\\nüèÜ BEST MODEL:\", best_name)\n",
    "print(\"üî• BEST AUC:\", best_auc)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE MODEL FOR BACKEND\n",
    "# ============================================================\n",
    "\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"exohabitai_model.pkl\")\n",
    "\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "print(\"üíæ Model Saved:\", MODEL_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# CREATE RANKED DATASET (DASHBOARD FIX)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüåç Generating ranked_exoplanets.csv\")\n",
    "\n",
    "df[\"habitability_score\"] = best_model.predict_proba(X)[:,1]\n",
    "df[\"prediction\"] = best_model.predict(X)\n",
    "\n",
    "df = df.sort_values(\"habitability_score\", ascending=False)\n",
    "\n",
    "RANK_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "os.makedirs(RANK_DIR, exist_ok=True)\n",
    "\n",
    "RANK_PATH = os.path.join(RANK_DIR, \"ranked_exoplanets.csv\")\n",
    "\n",
    "df.to_csv(RANK_PATH, index=False)\n",
    "\n",
    "print(\"üìä Ranked Dataset Saved:\", RANK_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE IMPORTANCE VISUAL (RF ONLY)\n",
    "# ============================================================\n",
    "\n",
    "if best_name == \"RandomForest\":\n",
    "\n",
    "    importances = best_model.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.barh(X.columns, importances)\n",
    "    plt.title(\"RandomForest Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# COMPLETE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüöÄ LEVEL-1200 WEEK3 ML PIPELINE COMPLETE\")\n",
    "print(\"‚úÖ Backend Ready\")\n",
    "print(\"‚úÖ Ranking API Ready\")\n",
    "print(\"‚úÖ Dashboard Sync Ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
