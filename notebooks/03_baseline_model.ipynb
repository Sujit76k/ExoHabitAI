{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üöÄ EXOHABITAI ‚Äî LEVEL-700 AUTO MODEL TRAINING PIPELINE\n",
    "# SINGLE CELL VERSION ‚Äî PRODUCTION READY\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "print(\"üöÄ ExoHabitAI ‚Äî Training Pipeline Started\")\n",
    "\n",
    "# ============================================================\n",
    "# üåå AUTO PROJECT ROOT DETECTION\n",
    "# ============================================================\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(CURRENT_DIR)\n",
    "\n",
    "DATA_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"processed\",\n",
    "    \"model_ready_exoplanets.csv\"\n",
    ")\n",
    "\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"exohabitai_model.pkl\")\n",
    "\n",
    "print(\"üìÇ Dataset:\", DATA_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found:\\n{DATA_PATH}\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ FEATURE SPLIT\n",
    "# ============================================================\n",
    "\n",
    "target = \"habitability\"\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "print(\"\\nüß† Feature Count:\", X.shape[1])\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ TRAIN TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train Size:\", X_train.shape)\n",
    "print(\"Test Size:\", X_test.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ BUILD MODELS (AUTO COMPARE)\n",
    "# ============================================================\n",
    "\n",
    "models = {\n",
    "\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=3000, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=12,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\"\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ TRAIN + EVALUATE\n",
    "# ============================================================\n",
    "\n",
    "for name, pipe in models.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Training {name}\")\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    results.append((name, auc, pipe))\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ AUTO SELECT BEST MODEL\n",
    "# ============================================================\n",
    "\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "best_name, best_auc, best_model = results[0]\n",
    "\n",
    "print(\"\\nüèÜ BEST MODEL:\", best_name)\n",
    "print(\"üî• BEST AUC:\", best_auc)\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ SAVE MODEL (BACKEND READY)\n",
    "# ============================================================\n",
    "\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "print(\"üíæ Model Saved:\", MODEL_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ CREATE RANKED DATASET (VERY IMPORTANT)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüåç Creating Ranked Exoplanets File...\")\n",
    "\n",
    "df[\"habitability_score\"] = best_model.predict_proba(X)[:,1]\n",
    "df[\"prediction\"] = best_model.predict(X)\n",
    "\n",
    "df = df.sort_values(\"habitability_score\", ascending=False)\n",
    "\n",
    "RANK_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"processed\",\n",
    "    \"ranked_exoplanets.csv\"\n",
    ")\n",
    "\n",
    "df.to_csv(RANK_PATH, index=False)\n",
    "\n",
    "print(\"üìä Ranked Dataset Saved:\", RANK_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# 9Ô∏è‚É£ QUICK FEATURE IMPORTANCE (RF ONLY)\n",
    "# ============================================================\n",
    "\n",
    "if best_name == \"RandomForest\":\n",
    "\n",
    "    importances = best_model.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.barh(X.columns, importances)\n",
    "    plt.title(\"RandomForest Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# üéâ LEVEL-700 TRAINING COMPLETE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüöÄ LEVEL-700 MODEL TRAINING COMPLETE\")\n",
    "print(\"‚úÖ Backend /predict API READY\")\n",
    "print(\"‚úÖ Ranking API READY\")\n",
    "print(\"‚úÖ Dashboard Sync READY\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
