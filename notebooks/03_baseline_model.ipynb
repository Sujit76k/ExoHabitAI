{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ExoHabitAI ‚Äî Training Pipeline Started\n",
      "üìÇ Searching dataset inside: d:\\Infosys Springboard Internship\\ExoHabitAI\\data\\processed\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "‚ùå No training dataset found inside:\nd:\\Infosys Springboard Internship\\ExoHabitAI\\data\\processed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DATA_PATH \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m     55\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå No training dataset found inside:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mDATA_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     56\u001b[39m     )\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Using Dataset:\u001b[39m\u001b[33m\"\u001b[39m, DATA_PATH)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# LOAD DATA\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: ‚ùå No training dataset found inside:\nd:\\Infosys Springboard Internship\\ExoHabitAI\\data\\processed"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üöÄ EXOHABITAI ‚Äî LEVEL-900 AUTO TRAINING PIPELINE (FINAL FIX)\n",
    "# AUTO DATASET DETECTOR + BACKEND SYNC + RANK GENERATOR\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "print(\"üöÄ ExoHabitAI ‚Äî Training Pipeline Started\")\n",
    "\n",
    "# ============================================================\n",
    "# üåå AUTO PROJECT ROOT DETECTION (ULTRA SAFE)\n",
    "# ============================================================\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(CURRENT_DIR)\n",
    "\n",
    "DATA_FOLDER = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "\n",
    "print(\"üìÇ Searching dataset inside:\", DATA_FOLDER)\n",
    "\n",
    "# ============================================================\n",
    "# üî• AUTO DATASET FINDER (NO MORE FILE ERRORS)\n",
    "# ============================================================\n",
    "\n",
    "possible_files = [\n",
    "    \"model_ready_exoplanets.csv\",\n",
    "    \"processed_model_ready_exoplanets.csv\",\n",
    "    \"final_model_ready_exoplanets.csv\"\n",
    "]\n",
    "\n",
    "DATA_PATH = None\n",
    "\n",
    "for f in possible_files:\n",
    "    test_path = os.path.join(DATA_FOLDER, f)\n",
    "    if os.path.exists(test_path):\n",
    "        DATA_PATH = test_path\n",
    "        break\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"‚ùå No training dataset found inside:\\n{DATA_FOLDER}\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Using Dataset:\", DATA_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# TARGET DETECTION\n",
    "# ============================================================\n",
    "\n",
    "if \"habitability\" not in df.columns:\n",
    "    raise ValueError(\"‚ùå Column 'habitability' not found in dataset\")\n",
    "\n",
    "target = \"habitability\"\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "print(\"üß† Feature Count:\", X.shape[1])\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# MODELS\n",
    "# ============================================================\n",
    "\n",
    "models = {\n",
    "\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression(max_iter=3000, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=12,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\"\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN + EVALUATE\n",
    "# ============================================================\n",
    "\n",
    "for name, pipe in models.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Training {name}\")\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    results.append((name, auc, pipe))\n",
    "\n",
    "# ============================================================\n",
    "# BEST MODEL\n",
    "# ============================================================\n",
    "\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "best_name, best_auc, best_model = results[0]\n",
    "\n",
    "print(\"\\nüèÜ BEST MODEL:\", best_name)\n",
    "print(\"üî• BEST AUC:\", best_auc)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE MODEL\n",
    "# ============================================================\n",
    "\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"backend\", \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"exohabitai_model.pkl\")\n",
    "\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "print(\"üíæ Model Saved:\", MODEL_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# CREATE RANKED DATASET (DASHBOARD FIX)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüåç Generating ranked_exoplanets.csv\")\n",
    "\n",
    "df[\"habitability_score\"] = best_model.predict_proba(X)[:,1]\n",
    "df[\"prediction\"] = best_model.predict(X)\n",
    "\n",
    "df = df.sort_values(\"habitability_score\", ascending=False)\n",
    "\n",
    "RANK_PATH = os.path.join(DATA_FOLDER, \"ranked_exoplanets.csv\")\n",
    "\n",
    "df.to_csv(RANK_PATH, index=False)\n",
    "\n",
    "print(\"üìä Ranked Dataset Saved:\", RANK_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE IMPORTANCE (RF)\n",
    "# ============================================================\n",
    "\n",
    "if best_name == \"RandomForest\":\n",
    "\n",
    "    importances = best_model.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.barh(X.columns, importances)\n",
    "    plt.title(\"RandomForest Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# COMPLETE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüöÄ LEVEL-900 TRAINING COMPLETE\")\n",
    "print(\"‚úÖ Backend Ready\")\n",
    "print(\"‚úÖ Ranking API Ready\")\n",
    "print(\"‚úÖ Dashboard Sync Ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
