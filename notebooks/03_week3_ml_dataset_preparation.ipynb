{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17889f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üöÄ EXOHABITAI ‚Äî LEVEL-900 ML DATASET PREPARATION PIPELINE\n",
    "# SINGLE CELL ‚Äî AUTO ROOT DETECTION + PRO FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üöÄ ExoHabitAI ‚Äî ML Dataset Preparation Started\")\n",
    "\n",
    "# ============================================================\n",
    "# üåå AUTO PROJECT ROOT DETECTION (VERY IMPORTANT)\n",
    "# ============================================================\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(CURRENT_DIR)\n",
    "\n",
    "INPUT_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"processed\",\n",
    "    \"cleaned_exoplanets.csv\"\n",
    ")\n",
    "\n",
    "OUTPUT_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"data\",\n",
    "    \"processed\",\n",
    "    \"model_ready_exoplanets.csv\"\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "print(\"üìÇ Input Dataset:\", INPUT_PATH)\n",
    "print(\"üìÇ Output Dataset:\", OUTPUT_PATH)\n",
    "print(\"üì° File Exists:\", os.path.exists(INPUT_PATH))\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ LOAD CLEAN DATASET\n",
    "# ============================================================\n",
    "\n",
    "if not os.path.exists(INPUT_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found:\\n{INPUT_PATH}\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH, low_memory=False)\n",
    "\n",
    "print(\"‚úÖ Dataset Loaded:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ MEMORY OPTIMIZATION (NASA BIG DATA SAFE)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüíæ Optimizing Memory...\")\n",
    "\n",
    "for col in df.select_dtypes(include=[\"float64\"]).columns:\n",
    "    df[col] = df[col].astype(\"float32\")\n",
    "\n",
    "for col in df.select_dtypes(include=[\"int64\"]).columns:\n",
    "    df[col] = df[col].astype(\"int32\")\n",
    "\n",
    "mem_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"Memory Usage After Optimization: {mem_mb:.2f} MB\")\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ SCIENTIFIC FEATURE SELECTION\n",
    "# ============================================================\n",
    "\n",
    "CORE_FEATURES = [\n",
    "    \"pl_rade\",\n",
    "    \"pl_eqt\",\n",
    "    \"pl_orbper\",\n",
    "    \"st_teff\",\n",
    "    \"st_mass\",\n",
    "    \"st_rad\"\n",
    "]\n",
    "\n",
    "existing_features = [c for c in CORE_FEATURES if c in df.columns]\n",
    "\n",
    "print(\"\\nüß† Using Scientific Features:\", existing_features)\n",
    "\n",
    "if len(existing_features) == 0:\n",
    "    raise Exception(\"‚ùå No scientific features found\")\n",
    "\n",
    "df_model = df[existing_features].copy()\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ ADVANCED FEATURE ENGINEERING (HSI + SCI)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüõ∞Ô∏è Creating Engineered Features...\")\n",
    "\n",
    "if \"pl_rade\" in df_model.columns:\n",
    "    df_model[\"rade_norm\"] = np.exp(-abs(df_model[\"pl_rade\"] - 1))\n",
    "\n",
    "if \"pl_eqt\" in df_model.columns:\n",
    "    df_model[\"eqt_norm\"] = np.exp(-abs(df_model[\"pl_eqt\"] - 288)/150)\n",
    "\n",
    "if \"st_teff\" in df_model.columns:\n",
    "    df_model[\"teff_norm\"] = np.exp(-abs(df_model[\"st_teff\"] - 5778)/2000)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üåç HSI ‚Äî Habitability Score Index\n",
    "# ------------------------------------------------------------\n",
    "if {\"rade_norm\",\"eqt_norm\"}.issubset(df_model.columns):\n",
    "    df_model[\"HSI\"] = (df_model[\"rade_norm\"] + df_model[\"eqt_norm\"]) / 2\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ‚≠ê SCI ‚Äî Stellar Compatibility Index\n",
    "# ------------------------------------------------------------\n",
    "if \"teff_norm\" in df_model.columns:\n",
    "    df_model[\"SCI\"] = df_model[\"teff_norm\"]\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ AUTO TARGET GENERATION (HABITABILITY LABEL)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüß™ Generating Habitability Label...\")\n",
    "\n",
    "conditions = []\n",
    "\n",
    "if \"pl_rade\" in df_model.columns:\n",
    "    conditions.append((df_model[\"pl_rade\"] >= 0.5) & (df_model[\"pl_rade\"] <= 2))\n",
    "\n",
    "if \"pl_eqt\" in df_model.columns:\n",
    "    conditions.append((df_model[\"pl_eqt\"] >= 200) & (df_model[\"pl_eqt\"] <= 350))\n",
    "\n",
    "if len(conditions) > 0:\n",
    "    combined = conditions[0]\n",
    "    for cond in conditions[1:]:\n",
    "        combined &= cond\n",
    "\n",
    "    df_model[\"habitability\"] = combined.astype(int)\n",
    "else:\n",
    "    df_model[\"habitability\"] = 0\n",
    "\n",
    "print(\"üåç Habitable planets:\", df_model[\"habitability\"].sum())\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ HANDLE MISSING VALUES (MODEL SAFE)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüßπ Filling Missing Values...\")\n",
    "\n",
    "df_model = df_model.replace([np.inf, -np.inf], np.nan)\n",
    "df_model = df_model.fillna(df_model.median(numeric_only=True))\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ FINAL DATASET CHECK\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüìä Final Dataset Shape:\", df_model.shape)\n",
    "print(\"Columns:\", list(df_model.columns))\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ SAVE MODEL-READY DATASET\n",
    "# ============================================================\n",
    "\n",
    "df_model.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"\\nüíæ Model Ready Dataset Saved Successfully!\")\n",
    "print(\"‚úÖ Path:\", OUTPUT_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# üéâ LEVEL-900 PREPARATION COMPLETE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüöÄ Dataset Ready For:\")\n",
    "print(\"‚úÖ Week3 Training Pipeline\")\n",
    "print(\"‚úÖ Backend Model Deployment\")\n",
    "print(\"‚úÖ Ranking Engine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
